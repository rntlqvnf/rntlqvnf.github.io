---
title: "리뷰어들의 질문 패턴을 이해하기"
layout: profession-post
categories:
  - Reflections
toc: true
toc_sticky: true
type: profession
---

### 연구란 리뷰어의 질문을 디펜스하는 과정

연구 생활을 수년 하면서 깨닫는 것은, 연구란 결국 질문에 대한 대답을 계속 해나가는 과정이라는 점이다. 어떤 문제가 있을지 질문하고 그에 대한 답을 찾으며, 문제를 찾았다면 그것을 해결하기 위한 답을 다시 질문한다. 답을 찾았다면, 그것이 정말 옳은지 또다시 질문한다. 논문은 이 끝없는 질문과 대답의 기록이다.

리뷰어는 그 기록을 읽으며, 자신의 질문에 대해 이미 논문에 답이 적혀있는지, 그리고 그 답이 타당한지 검증한다. 연구자는 리뷰어의 질문을 미리 예상하고, 그에 대한 답을 논문에 충분히 담아내야 한다.

결국 '연구 실력'이란 리뷰어의 질문 패턴을 얼마나 잘 이해하고, 그에 대한 답을 논문에 미리 설득력 있게 담아내느냐로 정의될 수 있다. 박사과정은 그런 질문 패턴을 몸으로 익히는 시간이며, 지도교수가 엄격한 리뷰어일수록 그 패턴을 더 빠르고 깊게 익히게 된다.

### 자주 나오는 리뷰어의 질문 패턴

리뷰어의 질문 패턴은 대체로 비슷하다. 이를 크게 네 가지, **의심(Skepticism)**, **비교(Comparison)**, **한계(Scope)**, 그리고 **호기심(Curiosity)** 으로 분류할 수 있다.

#### 1. 의심 (Skepticism): "그 주장이 정말 맞습니까?"

리뷰어는 연구자의 주장이 정말 옳은지 근본적으로 의심한다. 그래서 연구자가 주장하는 핵심 아이디어가 타당한지, 실험 결과가 그 주장을 뒷받침하는지, 그리고 근거가 충분한지 꼼꼼히 살핀다.

이 질문은 보통 연구자의 주장이 과장되어 보이거나, 실험 결과가 비현실적으로 좋아 보이거나, 주장을 뒷받침하는 근거가 부족해 보일 때 등장한다. 구체적으로. 다양한 패턴이 있다.

1.  **문제 전제 공격 (The "Is-it-really-a-problem?" Attack)**
    * "SOTA 시스템 `GraphChi`가 P1~P4 문제를 겪는다고 하셨는데, 그건 튜닝을 잘못했기 때문 아닐까요? 저희 랩에서 돌렸을 때는 `PSW` 모델이 그 정도까지 비효율적이지 않았습니다."
    * "논문에서 제시한 P1~P4 문제는 실제로 존재하는 문제인가요? 기존 연구들에서는 그런 문제가 보고된 적이 없습니다."

2.  **가정 공격 (The "Assumption" Attack)**
    * "제안하신 모델이 100억 간선(edge) 그래프까지 스케일 된다고 하셨는데, 이는 사용하신 데이터셋(e.g., ClueWeb)의 특정 분포 특성 때문일 수 있습니다. 파워로(power-law) 분포가 더 극단적인 실제 소셜 그래프에서도 동일한 가정이 성립합니까?"

3.  **기술적 타당성 공격 (The "Feasibility" Attack)**
    * "제안하신 `FINDNEC` 알고리즘의 시간 복잡도가 $O(N \log N)$이라고 하셨는데, 최악의 경우(worst-case) 모든 정점이 동일한 이웃 집합을 가질 때 $O(N^2)$이 되는 반례(counterexample)가 존재합니다. 이 부분을 다시 분석해 주시겠습니까?"
    * "메모리 사용량이 적다고 하셨지만, 제안하신 인덱스 구조는 데이터 편향(skew)이 심할 경우 특정 파티션에 데이터가 몰려 메모리 요구량이 급증할 것 같습니다. 이에 대한 분석이 있습니까?"

#### 2. 비교 (Comparison): "그게 SOTA보다 낫다는 것을 어떻게 압니까?"

리뷰어는 연구자가 제시하는 방법이 기존의 SOTA(State-of-the-Art) 방법보다 낫다는 것을 의심한다. 그래서 제안하는 방법이 SOTA와 비교해 정말 더 나은지, 그리고 그 비교가 '공정하게' 이루어졌는지 꼼꼼히 살핀다.

1.  **누락된 SOTA 공격 (The "Missing Baseline" Attack)**
    * "실험 결과를 잘 봤습니다. 그런데 왜 최근에 SIGMOD'17에서 나온 `[경쟁 시스템 Y]`와의 비교는 빠져있습니까? 그 시스템이 이 문제를 더 잘 푸는 것으로 알고 있습니다."

2.  **불공정 튜닝 공격 (The "Unfair Tuning" Attack)**
    * "Figure 1에서 `Gemini`가 OOM(Out-of-Memory)으로 중단되었는데, `Gemini`의 힙 메모리 설정은 얼마로 하셨습니까? 저희가 보기엔 경쟁 시스템의 튜닝을 일부러 비관적으로(pessimistically) 하신 것 같습니다."

3.  **편향된 워크로드 공격 (The "Biased Workload" Attack)**
    * "실험에 사용하신 TPC-H 벤치마크는 제안하신 `TurboGraph++`에 유리한 데이터 분포를 가진 것 같습니다. 데이터 분포가 다른 실제 소셜 네트워크 데이터(e.g., Twitter)에서도 동일한 성능 향상을 보장할 수 있습니까?"

#### 3. 한계 (Scope): "그 방법이 어디까지 통용됩니까?"

리뷰어는 제안된 방법의 한계를 파악하려고 한다. 그래서 이 방법이 어떤 상황에서 잘 작동하고, 어떤 상황에서는 잘 작동하지 않는지 그 경계(boundary)를 꼼꼼히 살핀다.

1.  **일반화 가능성 질문 (The "Generalizability" Probe)**
    * "제안하신 `pin-and-slide` 모델은 FlashSSD에서는 잘 작동하는 것을 확인했습니다. 하지만 만약 백엔드 스토리지가 HDD라면 이 모델이 오히려 성능 저하를 일으키지 않을까요?"

2.  **한계점 확인 질문 (The "Limitation" Probe)**
    * "이 시스템의 근본적인 한계(fundamental limitation)는 무엇이라고 생각하십니까? 예를 들어, 어떤 종류의 쿼리에서는 `TurboGraph++`가 `Gemini`보다 항상 느릴 수밖에 없는지 궁금합니다."

3.  **파라미터 민감도 질문 (The "Sensitivity" Probe)**
    * "제안하신 `BBP` 파티셔닝에 `p`, `q`, `r` 등 여러 파라미터가 있는데, 이 파라미터 튜닝이 성능에 얼마나 민감합니까? 사용자가 이걸 쉽게 튜닝할 수 있나요?"

#### 4. 호기심 (Curiosity): "이 방법을 더 확장할 수는 없나요?"

리뷰어가 제안한 방법을 더 확장할 수 있는지 궁금해하는, 대체로 긍정적인 의도의 질문이다. 제안한 방법이 다른 문제에도 적용될 수 있는지, 혹은 더 발전시킬 수 있는지 관심을 보인다.

1.  **확장/응용 질문 (The "Extension" Probe)**
    * "정말 훌륭한 연구입니다. 이 `nested windowed streaming` 아이디어를 혹시 그래프가 아닌 시계열(Time-series) 데이터베이스의 윈도우 처리에도 적용해 볼 생각을 해보셨습니까?"

2.  **'왜?' 질문 (The "Why" Probe)**
    * "실험 결과 중 한 부분이 매우 흥미로웠습니다. 데이터셋 A에서는 기법 X가, 데이터셋 B에서는 기법 Y가 더 빨랐는데, 그 근본적인 이유가 무엇이라고 분석하십니까?"

3.  **관련 연구 질문 (The "Connection" Probe)**
    * "(자신의 연구를 언급하며) 저희는 최근 [관련 연구]를 하고 있는데, 오늘 제안하신 아이디어가 저희 문제를 푸는 데 큰 도움이 될 것 같습니다. 혹시 [특정 세부 사항]에 대해 더 자세히 설명해 주실 수 있습니까?"

### 예상 질의응답 목록을 만들어라

리뷰어의 질문 패턴을 이해했다면, 이제 **예상 질의응답 목록(FAQ)** 을 만들어야 한다. 논문에 제기될 법한 질문들을 미리 뽑아내고, 그에 대한 답변을 미리 준비하는 것이다. 이 목록을 만들면 논문 작성 과정에서 어떤 부분을 더 보강해야 할지 명확해지고, 실제 리뷰어의 질문이나 발표 Q&A 세션에서 더 효과적으로 대응할 수 있다.